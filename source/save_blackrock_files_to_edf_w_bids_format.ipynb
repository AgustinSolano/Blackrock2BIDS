{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Blackrock iEEG files to EDF format following BIDS structure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este script permite tomar los datos originales en el formato de salida del sistema Blackrock (.nev, .ns3, ..) y guardarlo en otro directorio que sigue la estructura BIDS. Se utilizará el formato EDF para guardar los archivos de iEEG.\n",
    "\n",
    "Además, con ayuda de BIDS, se guardarán archivos accesorios con los eventos que fueron enviados durante la tarea, para posteriormente levantarlos con MNE-Python (u otro software)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANTE**\n",
    "\n",
    "En los registros que tomo pueden pasar dos cosas: los correspondiente a todas las tareas evaluadas (VMA, MSL) se encuentra en un único archivo o cada tarea tiene su archivo por separado. Por lo tanto, este script me permite también separar las tareas en caso de ser necesario. Eso se realiza a mano indicando el punto en el cual producir la division.\n",
    "\n",
    "Otro inconveniente que puede suceder es que haya eventos incorrectos o repetidos (por negligencia mia). Hay algunas lineas de codigos dedicadas a solucionar esos inconvenientes. --> ESO ESTA EN OTRO SCRIPT\n",
    "\n",
    "**CHEQUEAR TODOS LOS PASOS!!**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo.rawio import BlackrockRawIO\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne_bids \n",
    "import mne_bids.utils "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .nev3 Blackrock file, return neo reader\n",
    "def load_original_ieeg_nev3(filename):\n",
    "    \"\"\" Funcion para levantar una senal iEEG de Blackrock tipo nev3.\n",
    "    filename : path y nombre completo del archivo a levantar\n",
    "    Return: reader de la libreria 'neo' \n",
    "     \"\"\"\n",
    "    reader = BlackrockRawIO(filename=filename, nsx_to_load=3)\n",
    "    reader.parse_header()\n",
    "    return reader\n",
    "\n",
    "# Look for a specific sequence in numpy array\n",
    "def search_sequence_numpy(arr,seq):\n",
    "    \"\"\" Find sequence in an array using NumPy only.\n",
    "\n",
    "    Parameters\n",
    "    ----------    \n",
    "    arr    : input 1D array\n",
    "    seq    : input 1D array\n",
    "\n",
    "    Output\n",
    "    ------    \n",
    "    Output : 1D Array of indices in the input array that satisfy the \n",
    "    matching of input sequence in the input array.\n",
    "    In case of no match, an empty list is returned.\n",
    "\n",
    "    Source: https://stackoverflow.com/questions/36522220/searching-a-sequence-in-a-numpy-array\n",
    "    \"\"\"\n",
    "\n",
    "    # Store sizes of input array and sequence\n",
    "    Na, Nseq = arr.size, seq.size\n",
    "\n",
    "    # Range of sequence\n",
    "    r_seq = np.arange(Nseq)\n",
    "\n",
    "    # Create a 2D array of sliding indices across the entire length of input array.\n",
    "    # Match up with the input sequence & get the matching starting indices.\n",
    "    M = (arr[np.arange(Na-Nseq+1)[:,None] + r_seq] == seq).all(1)\n",
    "\n",
    "    # Get the range of those indices as final output\n",
    "    if M.any() >0:\n",
    "        return np.where(np.convolve(M,np.ones((Nseq),dtype=int))>0)[0]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Create mne raw dataset from neo reader\n",
    "def create_mne_dataset_from_neoReader(reader,ev_timestamps_sfreq=30000):\n",
    "    \"\"\" Create mne dataset from neo reader \n",
    "    reader: objeto reader de la libreria neo\n",
    "    ev_timestamps_sfreq: \"frecuencia de muestreo\" o resolucion temporal del canal de los eventos digitales\n",
    "    Asume: block=0, segment=0, time_start=0, time_stop=fin del archivo\n",
    "    Return: raw signal en Volts\n",
    "    \"\"\"\n",
    "\n",
    "    #Extraigo las senales de todos los canales, de todo el tiempo\n",
    "    raw_signal = reader.get_analogsignal_chunk(block_index=0, seg_index=0, i_start=0, i_stop=None)\n",
    "    raw_signal = raw_signal*(1e-6) # --> para convertir a Volts\n",
    "    sampling_rate = reader.get_signal_sampling_rate()\n",
    "    \n",
    "    #Extraigo los nombres de los canales del reader\n",
    "    ch_names = [reader.header[\"signal_channels\"][idx][0] for idx in range(raw_signal.shape[1])]\n",
    "    ch_types = ['seeg'] * len(ch_names)  \n",
    "\n",
    "    #Se indican los canales de tipo ECG, en caso de haber sido registrados\n",
    "    indx_ECG_chann = [i for i, s in enumerate(ch_names) if 'ECG' in s]\n",
    "    for i in indx_ECG_chann:\n",
    "        ch_types[i] = 'ecg' \n",
    "    \n",
    "    #Info mne\n",
    "    info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=sampling_rate)\n",
    "    \n",
    "    #Creacion del dataset mne\n",
    "    raw_mne = mne.io.RawArray(raw_signal.T, info)\n",
    "\n",
    "    #Creacion de canal para incluir la informacion de eventos\n",
    "    #Originalmente es una senal digital que se transforma a analogica para crear el dataset de mne\n",
    "    stim_chann = np.zeros((1, raw_signal.T.shape[1]))\n",
    "    info_stim = mne.create_info(['STIM'], raw_mne.info['sfreq'], ['stim'])\n",
    "    stim_raw = mne.io.RawArray(stim_chann, info_stim)\n",
    "    raw_mne.add_channels([stim_raw], force_update_info=True)\n",
    "\n",
    "    #Inclusion de los eventos a partir de la informacion del registro original\n",
    "    ev_timestamps, ev_durations, ev_labels = reader.get_event_timestamps(block_index=0, seg_index=0, event_channel_index=0,\n",
    "                    t_start=None, t_stop=None)\n",
    "\n",
    "    ev_sample = np.floor(ev_timestamps*sampling_rate/ev_timestamps_sfreq).astype(int)\n",
    "    #Se conservan los 8 bits con el codigo del evento\n",
    "    ev_labels_num = ev_labels.astype(int) & 0xff\n",
    "    \n",
    "    # Ambas tareas\n",
    "    # 2 --> 64: Inicio Baseline --> en el registro original es 2, lo transformo a 64\n",
    "    # 8 --> 128: Fin Baseline  --> en el registro original es 8, lo transformo a 128\n",
    "\n",
    "    # Eventos para la tarea MSL:\n",
    "    # 4: Inicio REST\n",
    "    # 16: Inicio TASK\n",
    "\n",
    "    # Eventos para la tarea VMA:\n",
    "    # 4: Inicio TRIAL\n",
    "    # 8: Inicio MOVIMIENTO\n",
    "    # 16: Fin MOVIMIENTO\n",
    "    # 32: Fin TRIAL\n",
    "\n",
    "    posibles_events = [2, 8, 4, 16, 32]\n",
    "    valid_events = np.isin(ev_labels_num,posibles_events)\n",
    "    events_array = np.block([[ev_sample[valid_events]], [np.zeros(np.sum(valid_events))], [ev_labels_num[valid_events]]]).T\n",
    "    events_array = events_array.astype(int)\n",
    "\n",
    "    #Transformo los codigos de los eventos correspondientes a Inicio y Fin de Baseline porque coinciden con otros eventos\n",
    "    #   1. Se busca los indices de la ocurrencia de la secuencia 2-8, que indican en el inicio y fin del periodo de basline/rest\n",
    "    #   2. Reemplzaso la secuencia 2-8 por la secuencia 64-128\n",
    "    old_seq = [2,8]\n",
    "    new_seq = [64,128]\n",
    "    indxs_seq = search_sequence_numpy(events_array[:,2],np.array(old_seq))\n",
    "    events_array[indxs_seq,2] = np.tile(np.array(new_seq), int(indxs_seq.size/2))\n",
    "\n",
    "    \n",
    "    # ESTO ES SOLO PARA EL SUJETO 05, QUE LE FALTA UN TRIGGER DE FIN DE BASELINE en el tarea VMA\n",
    "    #events_array[-1][2] = 64\n",
    "    #events_array = np.row_stack((events_array,np.array([raw_mne.n_times-1, 0, 128])))\n",
    "\n",
    "    # Se agrega la informacion de los eventos como canal STIM\n",
    "    raw_mne.add_events(events_array, stim_channel='STIM', replace=True)\n",
    "\n",
    "    return raw_mne\n",
    "\n",
    "# Export/save .edf file from mne raw dataset\n",
    "def export_mne_to_edf_BIDSformat(raw_mne_in, root, subject, task_name, session_name, run, datatype, description = None, extension='.edf'):\n",
    "    \"\"\" Export mne dataset to .edf file using BIDS format\n",
    "    raw_mne: mne data set\n",
    "    root: BIDS root path\n",
    "    subject: subject name/code\n",
    "    task: task name\n",
    "    session: session name\n",
    "    run: run number\n",
    "    datatype: BIDS datatype\n",
    "    extension: por defecto la extension es .edf\n",
    "    \"\"\"\n",
    "\n",
    "    #subject = '07' \n",
    "    #task_name = task['vma']\n",
    "    #session_name = session['ses1']\n",
    "    #run = None\n",
    "    #datatype = 'ieeg'\n",
    "\n",
    "    events = mne.find_events(raw_mne_in, shortest_event=1, stim_channel='STIM')\n",
    "\n",
    "    if task_name == 'vma':\n",
    "\n",
    "        #Se filtran los eventos para consevar solo los que corresponden a la tarea, en caso de que haya alguno incorrecto\n",
    "        posibles_events_vma = [4, 8, 16, 32, 64, 128]     \n",
    "        valid_events_vma = np.isin(events[:,2],posibles_events_vma)\n",
    "        events = events[valid_events_vma,:]\n",
    "        events_id = {'start_bsl_rest': 64, 'stop_bsl_rest': 128, 'start_trial': 4, 'start_mov': 8, 'end_mov': 16, 'end_trial': 32}\n",
    "    \n",
    "    elif task_name == 'msl':\n",
    "        \n",
    "        #Se filtran los eventos para consevar solo los que corresponden a la tarea, en caso de que haya alguno incorrecto\n",
    "        posibles_events_msl = [4, 16, 64, 128]     \n",
    "        valid_events_msl = np.isin(events[:,2],posibles_events_msl)\n",
    "        events = events[valid_events_msl,:]\n",
    "        events_id = {'start_bsl_rest': 64, 'stop_bsl_rest': 128, 'inicio_msl_rest': 4, 'inicio_msl_task': 16}\n",
    "\n",
    "    BIDS_path = mne_bids.BIDSPath(root=root, subject=subject, task=task_name, session=session_name,\n",
    "                run=run, datatype=datatype, extension=extension, description = description)\n",
    "\n",
    "    raw_mne_in.drop_channels('STIM')\n",
    "\n",
    "    #Gardar el archivo tipo .edf siguiendo el formato BIDS\n",
    "    mne_bids.write_raw_bids(raw_mne_in, BIDS_path, format='EDF', symlink=False, empty_room=None, \n",
    "        allow_preload=True, overwrite=True, verbose=True, events = events, event_id = events_id)\n",
    "\n",
    "    #####\n",
    "    #bids_path = mne_bids.BIDSPath(root=root, subject=subject, task=task, session=session,\n",
    "    #                     run=run, datatype=datatype, extension=extension)\n",
    "                           \n",
    "    #mne.export.export_raw(bids_path.fpath, raw_mne, fmt='auto', physical_range='auto', add_ch_type=False, overwrite=False, verbose=None)\n",
    "    \n",
    "    return BIDS_path\n",
    "\n",
    "#Split mne dataset according to specific (start/stop) indexes \n",
    "def split_mne_dataset(raw_mne_in, start_indx, stop_indx):\n",
    "    \"\"\" Devuelve un nuevo dataset mne cortado segun los indices de comienzo y final\n",
    "    raw_mne_in: dataset mne original\n",
    "    start_indx, stop_indx: inidces utilizados para cortar el data set segun se necesite\n",
    "    Return: raw_mne_out es el dataset de salida cortado a partir de raw_mne_in\n",
    "    \"\"\"\n",
    "    data_signal = raw_mne_in.get_data(start=start_indx, stop=stop_indx, return_times=False)\n",
    "    raw_mne_out = mne.io.RawArray(data_signal, raw_mne_in.info)\n",
    "    del data_signal\n",
    "\n",
    "    return raw_mne_out\n",
    "\n",
    "# Add event by hand\n",
    "def add_event_manually(raw_mne_in):\n",
    "    \"\"\" Add a custom event to a mne object\n",
    "    \"\"\"\n",
    "    events = mne.find_events(raw_mne_in, shortest_event=1, stim_channel='STIM')\n",
    "    print(events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tareas posibles**: motor sequence learning (MSL) o visuomotor adaptation (VMA). Por ahora no tengo registros de sueño pero en el futuro podría haber.\n",
    "\n",
    "**Sesiones**: si bien hay una unica sesion convendría ponerle nombre en caso de que mas adeltante haga mas de una sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino los nombres de la tareas y de las sesiones\n",
    "task = {'msl':\"msl\",'vma':\"vma\",'sleep':\"sleep\"}\n",
    "session = {'ses1':'day1'}\n",
    "\n",
    "#Indicar nombre del directorio donde se debe guardar todo el arbol BIDS\n",
    "bids_root = '/home/lfa-01/Documentos/Datos_Proyecto_LFA-ENYS_BIDS'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se indica el nombre del archivo nev3 y se crea el reader con la libreria Neo. \n",
    "\n",
    "Indicar tambien el numero/codigo del sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = '05' # INDICAR CODIGO DE SUJETO \n",
    "files_separated = True # ELOS REGISTROS ESTÁN TODOS EN EL MISMO ARCHIVO O EN ARCHIVOS SEPARADOS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que todo el registro esté en un mismo archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los archivos están separados, se levanta cada uno donde corresponda.\n"
     ]
    }
   ],
   "source": [
    "if files_separated == False:\n",
    "    #INDICAR EL FILE PATH\n",
    "    nev_filename = '/home/lfa-01/Documentos/CopiaTemp_Testeos_Pacientes_ENYS_BIDS/sub-0XXX/ieeg/'\n",
    "    neo_reader = load_original_ieeg_nev3(nev_filename)\n",
    "    print(neo_reader)\n",
    "else:\n",
    "    print(\"Los archivos están separados, se levanta cada uno donde corresponda.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un dataset de mne a partir del reader Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los archivos están separados, se levanta cada uno donde corresponda.\n"
     ]
    }
   ],
   "source": [
    "if files_separated == False:\n",
    "    raw_mne = create_mne_dataset_from_neoReader(neo_reader)\n",
    "    print(raw_mne.info)\n",
    "else:\n",
    "    print(\"Los archivos están separados, se levanta cada uno donde corresponda.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sanity check se visualizan los eventos registrados para entender si el achivo contiene los entrenamientos msl y vma juntos o quedaron separados. En caso de que esten juntos hay que determinar la muestra que se utlizará para separarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los archivos están separados, se levanta cada uno donde corresponda.\n"
     ]
    }
   ],
   "source": [
    "if files_separated == False:\n",
    "    events = mne.find_events(raw_mne, stim_channel='STIM')\n",
    "    events\n",
    "    plt.plot(events[:,0],events[:,2])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Los archivos están separados, se levanta cada uno donde corresponda.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del raw_mne\n",
    "#del mne_aux\n",
    "#del mne_vma\n",
    "#del mne_msl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para gardar dataset como EDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para el registro de VMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlackrockRawIO: /home/lfa-01/Documentos/CopiaTemp_Testeos_Pacientes_ENYS_BIDS/sub-05/ieeg/UcidvjGmlifqkkjymEcf16_03_-20220316-110849-INST0\n",
      "nb_block: 1\n",
      "nb_segment:  [1]\n",
      "signal_streams: [nsx3 (chans: 64)]\n",
      "signal_channels: [TPI1, TPI2, TPI3, INSI1 ... HQD4 , HQD5 , HQD6 , HQD7]\n",
      "spike_channels: [ch65#0, ch66#0, ch67#0, ch68#0 ... ch109#0 , ch110#0 , ch111#0 , ch112#0]\n",
      "event_channels: [digital_input_port, serial_input_port, comments]\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=5899191\n",
      "    Range : 0 ... 5899190 =      0.000 ...  2949.595 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=5899191\n",
      "    Range : 0 ... 5899190 =      0.000 ...  2949.595 secs\n",
      "Ready.\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: TPI1, TPI2, TPI3, INSI1, INSI2, INSI3, INSI4, ECG1, ECG2, FOI3, ...\n",
      " chs: 62 sEEG, 2 ECG, 1 Stimulus\n",
      " custom_ref_applied: False\n",
      " dig: 0 items\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 65\n",
      " projs: []\n",
      " sfreq: 2000.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "if files_separated == False:\n",
    "    #INDICAR ESTE VALOR PARA DIVIDIR EL REGISTRO DONDE CORRESPONDA, CHEQUEAR QUE TAREA VA PRIMERO\n",
    "    max_indx = int(5.297E+6) #se utiliza la muestra/indice que corresponda según como haya quedado estrucutrado el registro\n",
    "    mne_vma = split_mne_dataset(raw_mne, 0, max_indx)\n",
    "    print(mne_vma.info)\n",
    "\n",
    "elif files_separated == True:\n",
    "    # INDICAR EL NOMBRE EL ARCHIVO CORRESPONDIENTE A LA TAREA VMA\n",
    "    nev_filename_vma = '/home/lfa-01/Documentos/CopiaTemp_Testeos_Pacientes_ENYS_BIDS/sub-05/ieeg/UcidvjGmlifqkkjymEcf16_03_-20220316-110849-INST0'\n",
    "    neo_reader_vma = load_original_ieeg_nev3(nev_filename_vma)\n",
    "    print(neo_reader_vma)\n",
    "\n",
    "    mne_vma = create_mne_dataset_from_neoReader(neo_reader_vma)\n",
    "    print(mne_vma.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neo_reader_vma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sanity check se visualizan los eventos registrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1284 events found\n",
      "Event IDs: [  2   4   8  16  32  64 128]\n",
      "[[1336226       0      64]\n",
      " [1337847       0     128]\n",
      " [1339458       0      32]\n",
      " ...\n",
      " [4985983       0      16]\n",
      " [4986383       0      32]\n",
      " [5077503       0       2]]\n"
     ]
    }
   ],
   "source": [
    "events_vma = mne.find_events(mne_vma, shortest_event=1, stim_channel='STIM')\n",
    "print(events_vma)\n",
    "plt.plot(events_vma[:,0],events_vma[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del registro correspondiente con extensión EDF y en formato BIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = task['vma']\n",
    "session_name = session['ses1']\n",
    "run = None\n",
    "datatype = 'ieeg'\n",
    "BIDS_path = export_mne_to_edf_BIDSformat(mne_vma, bids_root, subject, task_name, session_name, run, datatype, extension='.edf')\n",
    "\n",
    "print(BIDS_path.fpath)\n",
    "print(BIDS_path.root)\n",
    "print(BIDS_path.extension)\n",
    "print(BIDS_path.directory)\n",
    "print(BIDS_path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mne_vma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASO ESPECIAL\n",
    "Para el sujeto 05 hay muchos canales y tengo problemas para guardar su info de una sola vez, voy a separar el registro en canales de Hipocampo + STIM y demas canales + STIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HKI1', 'HKI2', 'HKI3', 'HKI4', 'HKI5', 'HKI6', 'HQI1', 'HQI2', 'HQI3', 'HQI4', 'HQI5', 'HQI6', 'HKD1', 'HKD2', 'HKD3', 'HKD4', 'HKD5', 'HKD6', 'HKD7', 'HKD8', 'HQD1', 'HQD2', 'HQD3', 'HQD4', 'HQD5', 'HQD6', 'HQD7', 'STIM']\n",
      "['TPI1', 'TPI2', 'TPI3', 'INSI1', 'INSI2', 'INSI3', 'INSI4', 'ECG1', 'ECG2', 'FOI3', 'FOI4', 'AMI1', 'AMI2', 'AMI3', 'AMI4', 'AMI5', 'AMI6', 'TPD1', 'TPD2', 'TPD3', 'TPD4', 'INSD1', 'INSD2', 'INSD3', 'INSD4', 'INSD5', 'INSD6', 'FOD1', 'FOD2', 'FOD3', 'FOD4', 'AMD1', 'AMD2', 'AMD3', 'AMD4', 'AMD5', 'AMD6', 'STIM']\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "mne_vma.info['ch_names']\n",
    "first_letter = 'H'\n",
    "\n",
    "# Words starting with specific letter\n",
    "chan_hipp = []\n",
    "chan_no_hipp = []\n",
    "\n",
    "for i in mne_vma.info['ch_names']:\n",
    "    if(i.find(first_letter) == 0 or i.find(first_letter.lower()) == 0):\n",
    "        chan_hipp.append(i)\n",
    "    else:\n",
    "        chan_no_hipp.append(i)\n",
    "\n",
    "# Se agrega canal 'STIM'\n",
    "chan_hipp.append('STIM')\n",
    "\n",
    "print(chan_hipp)\n",
    "print(chan_no_hipp)\n",
    "print(len(chan_no_hipp)+len(chan_hipp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "task_name = task['vma']\n",
    "session_name = session['ses1']\n",
    "run = None\n",
    "datatype = 'ieeg' \n",
    "description = 'chann_hipp'\n",
    "\n",
    "mne_vma_select = mne_vma.pick_channels(chan_hipp)\n",
    "mne_vma.info['ch_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIDS_path = export_mne_to_edf_BIDSformat(mne_vma_select, bids_root, subject, task_name, session_name, run, datatype, description = description, extension='.edf')\n",
    "\n",
    "print(BIDS_path.fpath)\n",
    "print(BIDS_path.root)\n",
    "print(BIDS_path.extension)\n",
    "print(BIDS_path.directory)\n",
    "print(BIDS_path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mne_vma_select"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para el registro de MSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlackrockRawIO: /home/lfa-01/Documentos/CopiaTemp_Testeos_Pacientes_ENYS_BIDS/sub-05/ieeg/UcidvjGmlifqkkjymEcf14_03_-20220315-111802-INST0\n",
      "nb_block: 1\n",
      "nb_segment:  [1]\n",
      "signal_streams: [nsx3 (chans: 64)]\n",
      "signal_channels: [TPI1, TPI2, TPI3, INSI1 ... HQD4 , HQD5 , HQD6 , HQD7]\n",
      "spike_channels: [ch65#0, ch66#0, ch67#0, ch68#0 ... ch109#0 , ch110#0 , ch111#0 , ch112#0]\n",
      "event_channels: [digital_input_port, serial_input_port, comments]\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=6098424\n",
      "    Range : 0 ... 6098423 =      0.000 ...  3049.211 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=6098424\n",
      "    Range : 0 ... 6098423 =      0.000 ...  3049.211 secs\n",
      "Ready.\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: TPI1, TPI2, TPI3, INSI1, INSI2, INSI3, INSI4, FOI1, FOI2, FOI3, ...\n",
      " chs: 64 sEEG, 1 Stimulus\n",
      " custom_ref_applied: False\n",
      " dig: 0 items\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 65\n",
      " projs: []\n",
      " sfreq: 2000.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "if files_separated == False:\n",
    "    #INDICAR ESTE VALOR PARA DIVIDIR EL REGISTRO DONDE CORRESPONDA, CHEQUEAR QUE TAREA VA PRIMERO\n",
    "    max_indx = int(5.297E+6) #se utiliza la muestra/indice que corresponda según como haya quedado estrucutrado el registro\n",
    "    mne_msl = split_mne_dataset(raw_mne, max_indx, None)\n",
    "    print(mne_msl.info)\n",
    "\n",
    "elif files_separated == True:\n",
    "    # INDICAR EL NOMBRE EL ARCHIVO CORRESPONDIENTE A LA TAREA MSL\n",
    "    nev_filename_msl = '/home/lfa-01/Documentos/CopiaTemp_Testeos_Pacientes_ENYS_BIDS/sub-05/ieeg/UcidvjGmlifqkkjymEcf14_03_-20220315-111802-INST0'\n",
    "    neo_reader_msl = load_original_ieeg_nev3(nev_filename_msl)\n",
    "    print(neo_reader_msl)\n",
    "\n",
    "    mne_msl = create_mne_dataset_from_neoReader(neo_reader_msl)\n",
    "    print(mne_msl.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del neo_reader_msl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 events found\n",
      "Event IDs: [  4   8  16  64 128]\n"
     ]
    }
   ],
   "source": [
    "events_msl = mne.find_events(mne_msl, stim_channel='STIM')\n",
    "events_msl\n",
    "plt.plot(events_msl[:,0],events_msl[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardado del registro correspondiente con extensión EDF y en formato BIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 events found\n",
      "Event IDs: [  4   8  16  64 128]\n",
      "Writing '/home/lfa-01/Documentos/Datos_Proyecto_LFA-ENYS_BIDS/participants.tsv'...\n",
      "Writing '/home/lfa-01/Documentos/Datos_Proyecto_LFA-ENYS_BIDS/participants.json'...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "task_name = task['msl']\n",
    "session_name = session['ses1']\n",
    "run = None\n",
    "datatype = 'ieeg'\n",
    "BIDS_path = export_mne_to_edf_BIDSformat(mne_msl, bids_root, subject, task_name, session_name, run, datatype, extension='.edf')\n",
    "\n",
    "print(BIDS_path.fpath)\n",
    "print(BIDS_path.root)\n",
    "print(BIDS_path.extension)\n",
    "print(BIDS_path.directory)\n",
    "print(BIDS_path.basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mne_msl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_neo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "634230b8d7e4f6b04c4231db8fb019704a09a31b79739d05e10d1af73b28e8f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
